{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Convert .sqlite to .csv ###\n",
    "\n",
    "# def sqlite2csv(input_filename, output_filename):\n",
    "#     db = sqlite3.connect(input_filename)\n",
    "#     cursor = db.cursor()\n",
    "#     cursor.execute('SELECT name FROM sqlite_master WHERE type=\"table\";')\n",
    "#     tables = cursor.fetchall()\n",
    "#     for table_name in tables:\n",
    "#         table_name = table_name[0]\n",
    "#         table = pd.read_sql_query('SELECT * FROM %s' % table_name, db)\n",
    "#         table.to_csv(table_name + '.csv', index_label='index')\n",
    "#     cursor.close()\n",
    "#     db.close()\n",
    "#     del table\n",
    "#     table_names = pd.DataFrame(tables)\n",
    "#     table_names.to_csv(output_filename)\n",
    "#     return table_names\n",
    "\n",
    "folder = 'data/'\n",
    "database_filename = folder + 'database.sqlite'\n",
    "csv_filename = folder + 'table_names.csv'\n",
    "# table_names = sqlite2csv(database_filename, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangvwk/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/zhangvwk/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "### Put .csv files into dataframes ###\n",
    "\n",
    "table_names = pd.read_csv(csv_filename, index_col=0)\n",
    "names = [name[0] for name in table_names.values]\n",
    "\n",
    "# Create dictionary\n",
    "df = {}\n",
    "for name in names:\n",
    "    df[name] = pd.read_csv(folder + name + '.csv', index_col=0)\n",
    "    del df[name].index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dict(dict_to_be_dumped, dict_name):\n",
    "    with open(dict_name + '.json', 'w') as f:\n",
    "        json.dump(dict_to_be_dumped, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning \n",
    "## Dataframe: 'user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62593 entries, 0 to 62592\n",
      "Data columns (total 22 columns):\n",
      "id              62593 non-null int64\n",
      "first_name      62593 non-null object\n",
      "last_name       62593 non-null object\n",
      "city            61163 non-null object\n",
      "country         62495 non-null object\n",
      "sex             62593 non-null int64\n",
      "height          62593 non-null int64\n",
      "weight          62593 non-null int64\n",
      "started         62593 non-null int64\n",
      "competitions    4888 non-null object\n",
      "occupation      11778 non-null object\n",
      "sponsor1        5355 non-null object\n",
      "sponsor2        2656 non-null object\n",
      "sponsor3        1497 non-null object\n",
      "best_area       15413 non-null object\n",
      "worst_area      220 non-null object\n",
      "guide_area      7755 non-null object\n",
      "interests       8577 non-null object\n",
      "birth           27856 non-null object\n",
      "presentation    6113 non-null object\n",
      "deactivated     62593 non-null int64\n",
      "anonymous       62593 non-null int64\n",
      "dtypes: int64(7), object(15)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df['user'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop useless user features ###\n",
    "\n",
    "useless_user_columns = ['first_name',\n",
    "                        'last_name',\n",
    "                        'city', \n",
    "                        'competitions', \n",
    "                        'occupation', \n",
    "                        'sponsor1', \n",
    "                        'sponsor2', \n",
    "                        'sponsor3', \n",
    "                        'best_area', \n",
    "                        'worst_area', \n",
    "                        'guide_area', \n",
    "                        'interests', \n",
    "                        'presentation', \n",
    "                        'deactivated', \n",
    "                        'anonymous']\n",
    "\n",
    "df['user'].drop(columns=useless_user_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangvwk/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### COUNTRY ###\n",
    "\n",
    "# Drop users with missing country\n",
    "df['user'].dropna(subset=['country'], inplace=True)\n",
    "\n",
    "# Drop users with invalid country\n",
    "df['user'] = df['user'][df['user']['country'].map(type) == str]\n",
    "df['user'] = df['user'][df['user']['country'].map(len) == 3]\n",
    "\n",
    "# Convert country to index\n",
    "countries = df['user']['country'].unique()\n",
    "country2idx = {}\n",
    "idx = 0\n",
    "for country in df['user']['country'].unique():\n",
    "    country2idx[country] = idx\n",
    "    df['user']['country'][df['user']['country'] == country] = idx\n",
    "    idx += 1\n",
    "    \n",
    "# Dump country2idx\n",
    "dump_dict(country2idx, 'country2idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEX ###\n",
    "\n",
    "# 0 is male, 1 is female\n",
    "df['user'].rename(columns={'sex':'is_female'}, inplace=True)\n",
    "# 255 is unlikely to be non-binary so drop 255\n",
    "df['user'].drop(index=list(df['user'][df['user']['is_female']==255].index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIRTH AND STARTED ###\n",
    "\n",
    "df['user']['birth'] = pd.to_datetime(df['user']['birth'], errors='coerce')\n",
    "df['user']['birth'] = [date.year for date in df['user']['birth']]\n",
    "df['user']['started'] = pd.to_datetime(df['user']['started'], errors='coerce', format='%Y')\n",
    "df['user']['started'] = [date.year for date in df['user']['started']]\n",
    "\n",
    "df['user'] = df['user'][df['user']['birth'] > 1940]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HEIGHT AND WEIGHT ###\n",
    "\n",
    "# Replace 0 values with null\n",
    "df['user']['height'].replace(0, np.nan, inplace=True)\n",
    "df['user']['weight'].replace(0, np.nan, inplace=True)\n",
    "# df['user']['weight'] = df['user']['weight'].dropna()\n",
    "\n",
    "# Drop rows with null values in both height and weight\n",
    "# Since it's too hard to infer the correct values for either one based on the other features only\n",
    "# NOTE: losing around 50% of the dataset as a consequence\n",
    "df['user'].dropna(subset=['height', 'weight'], how='all', inplace=True)\n",
    "\n",
    "# Filter height to values between 140cm and 240cm\n",
    "df['user'] = df['user'][df['user']['height'] >= 140]\n",
    "df['user'] = df['user'][df['user']['height'] <= 240]\n",
    "\n",
    "# at this point, ~29k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangvwk/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/zhangvwk/.local/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Extract a complete dataset\n",
    "df_complete = df['user'].dropna(how='any')\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the complete dataset into train/test sets (80/20)\n",
    "df_train_orig, df_test = train_test_split(df_complete, test_size=0.2, random_state=229)\n",
    "\n",
    "# Apply additional bogus checks on both train and test sets\n",
    "df_train_orig['age_when_started_climbing'] = df_train_orig['started'] - df_train_orig['birth']\n",
    "df_train_orig = df_train_orig[df_train_orig['age_when_started_climbing'] >= 10]\n",
    "\n",
    "df_test['age_when_started_climbing'] = df_test['started'] - df_test['birth']\n",
    "df_test = df_test[df_test['age_when_started_climbing'] >= 10]\n",
    "\n",
    "# Drop weight as it is correlated with height\n",
    "df_train_orig.drop(columns='weight', inplace=True)\n",
    "df_test.drop(columns='weight', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14063 unique users in train_orig.\n",
      "There are 3521 unique users in test.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>is_female</th>\n",
       "      <th>height</th>\n",
       "      <th>started</th>\n",
       "      <th>birth</th>\n",
       "      <th>age_when_started_climbing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>4275</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31006</th>\n",
       "      <td>32351</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21852</th>\n",
       "      <td>22763</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27360</th>\n",
       "      <td>28503</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42850</th>\n",
       "      <td>45465</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id country  is_female  height  started   birth  \\\n",
       "4115    4275      21          0   176.0   2000.0  1974.0   \n",
       "31006  32351      12          0   175.0   2000.0  1989.0   \n",
       "21852  22763      14          0   175.0   2007.0  1988.0   \n",
       "27360  28503      21          0   159.0   1996.0  1976.0   \n",
       "42850  45465      21          0   180.0   2012.0  1984.0   \n",
       "\n",
       "       age_when_started_climbing  \n",
       "4115                        26.0  \n",
       "31006                       11.0  \n",
       "21852                       19.0  \n",
       "27360                       20.0  \n",
       "42850                       28.0  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('There are {} unique users in train_orig.'.format(len(df_train_orig['id'].unique())))\n",
    "print('There are {} unique users in test.'.format(len(df_test['id'].unique())))\n",
    "df_train_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interpolation on missing height data\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "incomplete = df['user'].drop(columns=['id', 'started'])\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "# Infer the missing data on: country, is_female, height, weight, birth\n",
    "imp.fit(incomplete)\n",
    "complete = pd.DataFrame(imp.transform(incomplete), columns=['country', 'is_female', 'height', 'weight', 'birth'])\n",
    "\n",
    "# Match the indexing\n",
    "complete.index = df['user'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the original with the interpolated height column\n",
    "complete = complete.astype(int)\n",
    "\n",
    "df['user']['height'] = complete['height']\n",
    "df['user']['birth'] = complete['birth']\n",
    "# # Drop the weight column since it is correlated with the height\n",
    "df['user'].drop(columns=['weight'], inplace=True)\n",
    "# print(df['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_started = df['user'].drop(columns=['id'])\n",
    "imp_started = IterativeImputer(max_iter=10, random_state=0)\n",
    "# Infer the missing started data on: country, is_female, height, weight, started, birth\n",
    "imp_started.fit(incomplete_started)\n",
    "complete_started = pd.DataFrame(imp_started.transform(incomplete_started), columns=['country', 'is_female', 'height', 'started', 'birth'])\n",
    "\n",
    "# Match the indexing\n",
    "complete_started.index = df['user'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the original with the interpolated height column\n",
    "complete_started = complete_started.astype(int)\n",
    "# complete_started\n",
    "df['user']['started'] = complete_started['started']\n",
    "# print(df['user'])\n",
    "\n",
    "# Add age_when_started_climbing column and drop those with values < 10 (years old)\n",
    "df['user']['age_when_started_climbing'] = df['user']['started'] - df['user']['birth']\n",
    "df['user'] = df['user'][df['user']['age_when_started_climbing'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint_df_user = df['user']\n",
    "df_train_imp = checkpoint_df_user.merge(df_test, how='outer', indicator=True)\n",
    "df_train_imp = df_train_imp[df_train_imp['_merge'] == 'left_only']\n",
    "df_train_imp = df_train_imp.drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18403 unique users in train_imp.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} unique users in train_imp.'.format(len(df_train_imp['id'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe: 'ascent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4111878 entries, 0 to 4111876\n",
      "Data columns (total 28 columns):\n",
      "id                      int64\n",
      "user_id                 float64\n",
      "grade_id                int64\n",
      "notes                   object\n",
      "raw_notes               int64\n",
      "method_id               int64\n",
      "climb_type              int64\n",
      "total_score             int64\n",
      "date                    float64\n",
      "year                    float64\n",
      "last_year               float64\n",
      "rec_date                float64\n",
      "project_ascent_date     float64\n",
      "name                    object\n",
      "crag_id                 float64\n",
      "crag                    object\n",
      "sector_id               float64\n",
      "sector                  object\n",
      "country                 object\n",
      "comment                 object\n",
      "rating                  float64\n",
      "description             object\n",
      "yellow_id               float64\n",
      "climb_try               float64\n",
      "repeat                  float64\n",
      "exclude_from_ranking    float64\n",
      "user_recommended        float64\n",
      "chipped                 float64\n",
      "dtypes: float64(15), int64(6), object(7)\n",
      "memory usage: 909.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df['ascent'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_ascent_columns = ['notes', \n",
    "                          'raw_notes',\n",
    "                          'total_score', \n",
    "                          'date', \n",
    "                          'last_year', \n",
    "                          'rec_date', \n",
    "                          'project_ascent_date', \n",
    "                          'name', \n",
    "                          'crag_id', \n",
    "                          'crag', \n",
    "                          'sector_id', \n",
    "                          'sector', \n",
    "                          'country', \n",
    "                          'comment', \n",
    "                          'rating', \n",
    "                          'description', \n",
    "                          'yellow_id', \n",
    "                          'climb_try', \n",
    "                          'repeat', \n",
    "                          'exclude_from_ranking', \n",
    "                          'user_recommended', \n",
    "                          'chipped']\n",
    "\n",
    "df['ascent'].drop(columns=useless_ascent_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ascent'] = df['ascent'].dropna().astype(int)\n",
    "df['ascent'].rename(columns={'climb_type':'is_bouldering'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 5, 4])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ascent']['method_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set method_id=5 to 3 since both designate onsight\n",
    "df['ascent']['method_id'][df['ascent']['method_id'] == 5] = 3\n",
    "# Set all other methods to be 0, as in not onsight\n",
    "df['ascent']['method_id'][df['ascent']['method_id'] != 3] = 0\n",
    "# Set method_id=3 to 1 as in onsight\n",
    "df['ascent']['method_id'][df['ascent']['method_id'] == 3] = 1\n",
    "# Rename 'method_id' as 'is_onsight' with now binary values only\n",
    "df['ascent'].rename(columns={'method_id':'is_onsight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4111877 entries, 0 to 4111876\n",
      "Data columns (total 6 columns):\n",
      "id               int64\n",
      "user_id          int64\n",
      "grade_id         int64\n",
      "is_onsight       int64\n",
      "is_bouldering    int64\n",
      "year             int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 219.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "checkpoint_df_ascent = df['ascent']\n",
    "checkpoint_df_ascent.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe: 'grade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83 entries, 0 to 82\n",
      "Data columns (total 14 columns):\n",
      "id                       83 non-null int64\n",
      "score                    83 non-null int64\n",
      "fra_routes               83 non-null object\n",
      "fra_routes_input         83 non-null int64\n",
      "fra_routes_selector      83 non-null int64\n",
      "fra_boulders             83 non-null object\n",
      "fra_boulders_input       83 non-null int64\n",
      "fra_boulders_selector    83 non-null int64\n",
      "usa_routes               47 non-null object\n",
      "usa_routes_input         83 non-null int64\n",
      "usa_routes_selector      83 non-null int64\n",
      "usa_boulders             45 non-null object\n",
      "usa_boulders_input       83 non-null int64\n",
      "usa_boulders_selector    83 non-null int64\n",
      "dtypes: int64(10), object(4)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df['grade'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a id to grade dict for later use\n",
    "id2grade = pd.Series(df['grade'][['id','fra_routes']].fra_routes.values,index=df['grade'][['id','fra_routes']].id).to_dict()\n",
    "dump_dict(id2grade, 'id2grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_grade_columns = ['score',\n",
    "                        'fra_routes',\n",
    "                        'fra_routes_input',\n",
    "                        'fra_routes_selector',\n",
    "                        'fra_boulders',\n",
    "                        'fra_boulders_input',\n",
    "                        'fra_boulders_selector',\n",
    "                        'usa_routes',\n",
    "                        'usa_routes_input',\n",
    "                        'usa_routes_selector',\n",
    "                        'usa_boulders',\n",
    "                        'usa_boulders_input',\n",
    "                        'usa_boulders_selector']\n",
    "\n",
    "checkpoint_df_grade = df['grade'].drop(columns=useless_grade_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83 entries, 0 to 82\n",
      "Data columns (total 1 columns):\n",
      "id    83 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Checkpoint\n",
    "checkpoint_df_grade.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14252"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_train_imp = df_train_imp.merge(checkpoint_df_ascent, left_on='id', right_on='user_id', suffixes=('_user','_ascent'))\n",
    "len(df_merged_train_imp['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keep only one user_id column\n",
    "df_merged_train_imp = df_merged_train_imp.drop(columns=['user_id', 'id_ascent']).rename(columns={'id_user':'user_id'})\n",
    "\n",
    "# Add an experience column for consistency check\n",
    "df_merged_train_imp['experience'] = df_merged_train_imp['year'] - df_merged_train_imp['started']\n",
    "# Keep only those with experience greater than 0 (otherwise bogus)\n",
    "df_merged_train_imp = df_merged_train_imp[df_merged_train_imp['experience'] >= 0]\n",
    "# Now drop experience and age_when_started_climbing\n",
    "df_merged_train_imp = df_merged_train_imp.drop(columns=['age_when_started_climbing', 'experience'])\n",
    "### NOTE: Deciding to leave the original features (started, birth, year) instead\n",
    "###       since they may account for the difference in training methods depending\n",
    "###       on the generation of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14241 unique users in merged_train_imp.\n"
     ]
    }
   ],
   "source": [
    "# df_merged_imp.to_csv('df_imputed.csv')\n",
    "print('There are {} unique users in merged_train_imp.'.format(len(df_merged_train_imp['user_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train_orig = df_train_orig.merge(checkpoint_df_ascent, left_on='id', right_on='user_id', suffixes=('_user','_ascent'))\n",
    "df_merged_test = df_test.merge(checkpoint_df_ascent, left_on='id', right_on='user_id', suffixes=('_user','_ascent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11233 unique users in merged_train_orig.\n",
      "There are 2813 unique users in merged_test.\n"
     ]
    }
   ],
   "source": [
    "# Keep only one user_id column\n",
    "df_merged_train_orig = df_merged_train_orig.drop(columns=['user_id', 'id_ascent']).rename(columns={'id_user':'user_id'})\n",
    "df_merged_test = df_merged_test.drop(columns=['user_id', 'id_ascent']).rename(columns={'id_user':'user_id'})\n",
    "\n",
    "# Add an experience column for consistency check\n",
    "df_merged_train_orig['experience'] = df_merged_train_orig['year'] - df_merged_train_orig['started']\n",
    "df_merged_test['experience'] = df_merged_test['year'] - df_merged_test['started']\n",
    "\n",
    "# Keep only those with experience greater than 0 (otherwise bogus)\n",
    "df_merged_train_orig = df_merged_train_orig[df_merged_train_orig['experience'] >= 0]\n",
    "df_merged_test = df_merged_test[df_merged_test['experience'] >= 0]\n",
    "\n",
    "# Now drop experience and age_when_started_climbing\n",
    "df_merged_train_orig = df_merged_train_orig.drop(columns=['age_when_started_climbing', 'experience'])\n",
    "df_merged_test = df_merged_test.drop(columns=['age_when_started_climbing', 'experience'])\n",
    "\n",
    "### NOTE: Deciding to leave the original features (started, birth, year) instead\n",
    "###       since they may account for the difference in training methods depending\n",
    "###       on the generation of the user.\n",
    "print('There are {} unique users in merged_train_orig.'.format(len(df_merged_train_orig['user_id'].unique())))\n",
    "print('There are {} unique users in merged_test.'.format(len(df_merged_test['user_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_train_orig: 1758212 data points.\n",
      "merged_train_imp: 2171996 data points.\n",
      "merged_test: 432737 data points.\n"
     ]
    }
   ],
   "source": [
    "print(\"merged_train_orig: {} data points.\".format(len(df_merged_train_orig)))\n",
    "print(\"merged_train_imp: {} data points.\".format(len(df_merged_train_imp)))\n",
    "print(\"merged_test: {} data points.\".format(len(df_merged_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train_orig.to_csv('ds_train_orig.csv')\n",
    "df_merged_train_imp.to_csv('ds_train_imp.csv')\n",
    "df_merged_test.to_csv('ds_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
